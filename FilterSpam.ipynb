{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Spam Filter Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#importing all libraries required"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sklearn processing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "\n",
    "#sklearn classification algorithms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "#sklearn classification model evaluation functions\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Since the data is already processed , we just store the processed data into a csv file.\n",
    "rf=pd.read_csv('spambase.data',header=None,delimiter=',')\n",
    "rf.columns=['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over','word_freq_remove','word_freq_internet',\n",
    "'word_freq_order','word_freq_mail','word_freq_receive','word_freq_will','word_freq_people','word_freq_report','word_freq_addresses',\n",
    "'word_freq_free','word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000',\n",
    "'word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet',\n",
    "'word_freq_857','word_freq_data','word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts',\n",
    "'word_freq_pm','word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu',\n",
    "'word_freq_table','word_freq_conference','char_freq_;','char_freq_(','char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average',\n",
    "'capital_run_length_longest','capital_run_length_total','class']\n",
    "rf.to_csv('SpamBase.csv',index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Load the data\n",
    "data=pd.read_csv(\"SpamBase.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n       'word_freq_business', 'word_freq_email', 'word_freq_you',\n       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n       'word_freq_original', 'word_freq_project', 'word_freq_re',\n       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n       'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n       'char_freq_$', 'char_freq_#', 'capital_run_length_average',\n       'capital_run_length_longest', 'capital_run_length_total', 'class'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect Data\n",
    "#Inspecting the column names\n",
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(4601, 58)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the number of rows and columns\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0             0.00            0.00  ...         0.00        0.000   \n1             0.00            0.94  ...         0.00        0.132   \n2             0.64            0.25  ...         0.01        0.143   \n3             0.31            0.63  ...         0.00        0.137   \n4             0.31            0.63  ...         0.00        0.135   \n\n   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0          0.0        0.778        0.000        0.000   \n1          0.0        0.372        0.180        0.048   \n2          0.0        0.276        0.184        0.010   \n3          0.0        0.137        0.000        0.000   \n4          0.0        0.135        0.000        0.000   \n\n   capital_run_length_average  capital_run_length_longest  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   capital_run_length_total  class  \n0                       278      1  \n1                      1028      1  \n2                      2259      1  \n3                       191      1  \n4                       191      1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Having a look at the data\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "word_freq_make                float64\nword_freq_address             float64\nword_freq_all                 float64\nword_freq_3d                  float64\nword_freq_our                 float64\nword_freq_over                float64\nword_freq_remove              float64\nword_freq_internet            float64\nword_freq_order               float64\nword_freq_mail                float64\nword_freq_receive             float64\nword_freq_will                float64\nword_freq_people              float64\nword_freq_report              float64\nword_freq_addresses           float64\nword_freq_free                float64\nword_freq_business            float64\nword_freq_email               float64\nword_freq_you                 float64\nword_freq_credit              float64\nword_freq_your                float64\nword_freq_font                float64\nword_freq_000                 float64\nword_freq_money               float64\nword_freq_hp                  float64\nword_freq_hpl                 float64\nword_freq_george              float64\nword_freq_650                 float64\nword_freq_lab                 float64\nword_freq_labs                float64\nword_freq_telnet              float64\nword_freq_857                 float64\nword_freq_data                float64\nword_freq_415                 float64\nword_freq_85                  float64\nword_freq_technology          float64\nword_freq_1999                float64\nword_freq_parts               float64\nword_freq_pm                  float64\nword_freq_direct              float64\nword_freq_cs                  float64\nword_freq_meeting             float64\nword_freq_original            float64\nword_freq_project             float64\nword_freq_re                  float64\nword_freq_edu                 float64\nword_freq_table               float64\nword_freq_conference          float64\nchar_freq_;                   float64\nchar_freq_(                   float64\nchar_freq_[                   float64\nchar_freq_!                   float64\nchar_freq_$                   float64\nchar_freq_#                   float64\ncapital_run_length_average    float64\ncapital_run_length_longest      int64\ncapital_run_length_total        int64\nclass                           int64\ndtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the data types of each feature\n",
    "data.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\ncount     4601.000000        4601.000000    4601.000000   4601.000000   \nmean         0.104553           0.213015       0.280656      0.065425   \nstd          0.305358           1.290575       0.504143      1.395151   \nmin          0.000000           0.000000       0.000000      0.000000   \n25%          0.000000           0.000000       0.000000      0.000000   \n50%          0.000000           0.000000       0.000000      0.000000   \n75%          0.000000           0.000000       0.420000      0.000000   \nmax          4.540000          14.280000       5.100000     42.810000   \n\n       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\ncount    4601.000000     4601.000000       4601.000000         4601.000000   \nmean        0.312223        0.095901          0.114208            0.105295   \nstd         0.672513        0.273824          0.391441            0.401071   \nmin         0.000000        0.000000          0.000000            0.000000   \n25%         0.000000        0.000000          0.000000            0.000000   \n50%         0.000000        0.000000          0.000000            0.000000   \n75%         0.380000        0.000000          0.000000            0.000000   \nmax        10.000000        5.880000          7.270000           11.110000   \n\n       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\ncount      4601.000000     4601.000000  ...  4601.000000  4601.000000   \nmean          0.090067        0.239413  ...     0.038575     0.139030   \nstd           0.278616        0.644755  ...     0.243471     0.270355   \nmin           0.000000        0.000000  ...     0.000000     0.000000   \n25%           0.000000        0.000000  ...     0.000000     0.000000   \n50%           0.000000        0.000000  ...     0.000000     0.065000   \n75%           0.000000        0.160000  ...     0.000000     0.188000   \nmax           5.260000       18.180000  ...     4.385000     9.752000   \n\n       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000   \nmean      0.016976     0.269071     0.075811     0.044238   \nstd       0.109394     0.815672     0.245882     0.429342   \nmin       0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.315000     0.052000     0.000000   \nmax       4.081000    32.478000     6.003000    19.829000   \n\n       capital_run_length_average  capital_run_length_longest  \\\ncount                 4601.000000                 4601.000000   \nmean                     5.191515                   52.172789   \nstd                     31.729449                  194.891310   \nmin                      1.000000                    1.000000   \n25%                      1.588000                    6.000000   \n50%                      2.276000                   15.000000   \n75%                      3.706000                   43.000000   \nmax                   1102.500000                 9989.000000   \n\n       capital_run_length_total        class  \ncount               4601.000000  4601.000000  \nmean                 283.289285     0.394045  \nstd                  606.347851     0.488698  \nmin                    1.000000     0.000000  \n25%                   35.000000     0.000000  \n50%                   95.000000     0.000000  \n75%                  266.000000     1.000000  \nmax                15841.000000     1.000000  \n\n[8 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>...</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.104553</td>\n      <td>0.213015</td>\n      <td>0.280656</td>\n      <td>0.065425</td>\n      <td>0.312223</td>\n      <td>0.095901</td>\n      <td>0.114208</td>\n      <td>0.105295</td>\n      <td>0.090067</td>\n      <td>0.239413</td>\n      <td>...</td>\n      <td>0.038575</td>\n      <td>0.139030</td>\n      <td>0.016976</td>\n      <td>0.269071</td>\n      <td>0.075811</td>\n      <td>0.044238</td>\n      <td>5.191515</td>\n      <td>52.172789</td>\n      <td>283.289285</td>\n      <td>0.394045</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.305358</td>\n      <td>1.290575</td>\n      <td>0.504143</td>\n      <td>1.395151</td>\n      <td>0.672513</td>\n      <td>0.273824</td>\n      <td>0.391441</td>\n      <td>0.401071</td>\n      <td>0.278616</td>\n      <td>0.644755</td>\n      <td>...</td>\n      <td>0.243471</td>\n      <td>0.270355</td>\n      <td>0.109394</td>\n      <td>0.815672</td>\n      <td>0.245882</td>\n      <td>0.429342</td>\n      <td>31.729449</td>\n      <td>194.891310</td>\n      <td>606.347851</td>\n      <td>0.488698</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.588000</td>\n      <td>6.000000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.065000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.276000</td>\n      <td>15.000000</td>\n      <td>95.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.380000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.160000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.188000</td>\n      <td>0.000000</td>\n      <td>0.315000</td>\n      <td>0.052000</td>\n      <td>0.000000</td>\n      <td>3.706000</td>\n      <td>43.000000</td>\n      <td>266.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.540000</td>\n      <td>14.280000</td>\n      <td>5.100000</td>\n      <td>42.810000</td>\n      <td>10.000000</td>\n      <td>5.880000</td>\n      <td>7.270000</td>\n      <td>11.110000</td>\n      <td>5.260000</td>\n      <td>18.180000</td>\n      <td>...</td>\n      <td>4.385000</td>\n      <td>9.752000</td>\n      <td>4.081000</td>\n      <td>32.478000</td>\n      <td>6.003000</td>\n      <td>19.829000</td>\n      <td>1102.500000</td>\n      <td>9989.000000</td>\n      <td>15841.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting the range and spread of values of each feature\n",
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "data.columns.isnull()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#x is the data to be trained on , y is the class values to test on\n",
    "x=data.iloc[:,:-1]\n",
    "y=data['class']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n0             0.00            0.00  ...                   0.0         0.00   \n1             0.00            0.94  ...                   0.0         0.00   \n2             0.64            0.25  ...                   0.0         0.01   \n3             0.31            0.63  ...                   0.0         0.00   \n4             0.31            0.63  ...                   0.0         0.00   \n\n   char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0        0.000          0.0        0.778        0.000        0.000   \n1        0.132          0.0        0.372        0.180        0.048   \n2        0.143          0.0        0.276        0.184        0.010   \n3        0.137          0.0        0.137        0.000        0.000   \n4        0.135          0.0        0.135        0.000        0.000   \n\n   capital_run_length_average  capital_run_length_longest  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   capital_run_length_total  \n0                       278  \n1                      1028  \n2                      2259  \n3                       191  \n4                       191  \n\n[5 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Having a look at the training data\n",
    "x.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 57) (4601,)\n"
     ]
    }
   ],
   "source": [
    "#Inspecting the shape of x and y\n",
    "print(x.shape,y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Normalizing the data using Min Max Scaler which will rescale the data so that all values will be in the range 0 and 1\n",
    "scaler=MinMaxScaler()\n",
    "#fit estimates the min and max values in the training data\n",
    "scaler.fit(x)\n",
    "#transform normalizes the data\n",
    "x_scaled=scaler.transform(x)\n",
    "x_scaled=pd.DataFrame(x_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classification Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naive Bayes Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8187296048288222 Standard Deviation 0.07743520649019187\n"
     ]
    }
   ],
   "source": [
    "classifier=GaussianNB()\n",
    "scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "print(\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8037465811562765 Standard Deviation 0.028343158792402096\n"
     ]
    }
   ],
   "source": [
    "classifier=SVC(kernel='rbf',gamma='auto')\n",
    "scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "print(\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9126204847684619 Standard Deviation 0.03333432664822017\n"
     ]
    }
   ],
   "source": [
    "classifier=DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "print(\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bagging Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9278416485900218 Standard Deviation 0.025217702820275856\n"
     ]
    }
   ],
   "source": [
    "classifier=BaggingClassifier(base_estimator=SVC())\n",
    "scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "print(\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-Nearest Neighbor Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   Accuracy 0.8856818824860889 Standard Deviation 0.03729749539243028\n",
      "2   Accuracy 0.8863340563991324 Standard Deviation 0.03663022381754964\n",
      "3   Accuracy 0.8876407620484768 Standard Deviation 0.03432656816907546\n",
      "4   Accuracy 0.8911166650947846 Standard Deviation 0.03166303411074864\n",
      "5   Accuracy 0.8895944543996981 Standard Deviation 0.03262755757031515\n",
      "6   Accuracy 0.894156370838442 Standard Deviation 0.030563466743595655\n",
      "7   Accuracy 0.8917655380552674 Standard Deviation 0.03206876907299416\n",
      "8   Accuracy 0.8950264076204849 Standard Deviation 0.030714880083931823\n",
      "9   Accuracy 0.8913331132698292 Standard Deviation 0.03673272837881641\n"
     ]
    }
   ],
   "source": [
    "#estimating optimal value of k\n",
    "for i in range(1,10):\n",
    "    classifier=KNeighborsClassifier(n_neighbors=i,weights='distance')\n",
    "    scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "    print(i,\" \",\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8913331132698292 Standard Deviation 0.03673272837881641\n"
     ]
    }
   ],
   "source": [
    "#optimal value is 7 because we have even number of classes to be predicted ,inorder to avoid ties we need to chose a odd value of k\n",
    "k_classifier=KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
    "scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "print(\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9391412807695936 Standard Deviation 0.035029700844193566\n"
     ]
    }
   ],
   "source": [
    "classifier=RandomForestClassifier(criterion=\"entropy\",random_state=0)\n",
    "scores=cross_val_score(classifier,x_scaled,y,cv=10)\n",
    "print(\"Accuracy\",np.mean(scores),\"Standard Deviation\",scores.std())\n",
    "#The best performing model is Random Forest Classifier due to its high accuracy compared to other models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating the Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best Performing Model-Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#k fold Cross validation\n",
    "kcv=KFold(n_splits=10,shuffle=True)\n",
    "model=RandomForestClassifier(criterion=\"entropy\",random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "sumE=0\n",
    "#number of folds k=10\n",
    "k=10\n",
    "i_list=[]\n",
    "false_positive_list=[]\n",
    "false_negative_list=[]\n",
    "error_rate_list=[]\n",
    "accuracy_list=[]\n",
    "for i in range(1,k+1):\n",
    "    result=next(kcv.split(x_scaled),None)\n",
    "\n",
    "    #splitting into train and test sets\n",
    "    x_train=x_scaled.iloc[result[0]]\n",
    "    x_test=x_scaled.iloc[result[1]]\n",
    "    y_train=y.iloc[result[0]]\n",
    "    y_test=y.iloc[result[1]]\n",
    "\n",
    "    #fitting the model\n",
    "    model.fit(x_train,y_train)\n",
    "    #predicting the values\n",
    "    y_pred=model.predict(x_test)\n",
    "\n",
    "    conf_matrix=metrics.confusion_matrix(y_test,y_pred)\n",
    "    #false positive is at [0][1] of 2X2 confusion matrix\n",
    "    fp=conf_matrix[0][1]\n",
    "    #false negative is at [1][0] of 2X2 confusion matrix\n",
    "    fn=conf_matrix[1][0]\n",
    "    #true negative is at [0][0] of 2X2 confusion matrix\n",
    "    tn=conf_matrix[0][0]\n",
    "    #true positive is at [1][1] of 2X2 confusion matrix\n",
    "    tp=conf_matrix[1][1]\n",
    "    #false positive rate\n",
    "    fpr=(fp/(fp+tn))\n",
    "    #false negative rate\n",
    "    fnr=(fn/(fn+tp))\n",
    "    #overall error rate\n",
    "    err=((fp+fn)/(tp+tn+fp+fn))\n",
    "    #sum of all error rates\n",
    "    sumE=sumE+err\n",
    "\n",
    "    i_list.append(i)\n",
    "    false_positive_list.append(fpr)\n",
    "    false_negative_list.append(fnr)\n",
    "    error_rate_list.append(err)\n",
    "\n",
    "    #calculating accuracy\n",
    "    accuracy_list.append(metrics.accuracy_score(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+-----------------------+--------------+------------+\n",
      "| Fold Number   |   False Positive Rate |   False Negative Rate |   Error Rate |   Accuracy |\n",
      "|---------------+-----------------------+-----------------------+--------------+------------|\n",
      "| 1             |             0.0262172 |             0.0824742 |    0.0498915 |   0.950108 |\n",
      "| 2             |             0.0149813 |             0.0515464 |    0.0303688 |   0.969631 |\n",
      "| 3             |             0.018315  |             0.0478723 |    0.0303688 |   0.969631 |\n",
      "| 4             |             0.0206186 |             0.0529412 |    0.032538  |   0.967462 |\n",
      "| 5             |             0.0252708 |             0.0380435 |    0.0303688 |   0.969631 |\n",
      "| 6             |             0.0316901 |             0.0564972 |    0.0412148 |   0.958785 |\n",
      "| 7             |             0.0262172 |             0.0670103 |    0.0433839 |   0.956616 |\n",
      "| 8             |             0.0173611 |             0.0924855 |    0.0455531 |   0.954447 |\n",
      "| 9             |             0.0376712 |             0.0946746 |    0.0585683 |   0.941432 |\n",
      "| 10            |             0.016835  |             0.0670732 |    0.0347072 |   0.965293 |\n",
      "| Average       |             0.0235178 |             0.0650618 |    0.0396963 |   0.960304 |\n",
      "+---------------+-----------------------+-----------------------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "i_list.append(\"Average\")\n",
    "false_positive_list.append(np.mean(false_positive_list))\n",
    "false_negative_list.append(np.mean(false_negative_list))\n",
    "error_rate_list.append(np.mean(error_rate_list))\n",
    "accuracy_list.append(np.mean(accuracy_list))\n",
    "\n",
    "from tabulate import tabulate\n",
    "df=pd.DataFrame({\"Fold Number\":i_list,\"False Positive Rate\":false_positive_list,\"False Negative Rate\":false_negative_list,\"Error Rate\":error_rate_list,\"Accuracy\":accuracy_list})\n",
    "df.set_index([\"Fold Number\"],inplace=True)\n",
    "print(tabulate(df,headers='keys',tablefmt='psql'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}